\section{Постановка проблемы}
\label{sec_problem}

По заявлениям разработчиков, сериализация и десериализация сообщений происходит достаточно быстро, однако
на практике при работе с массивными protobuf-сообщениями существует ряд задач, в которых десериализация является самой затратной операцией.
Массивными будем называть сообщения, имеющие большое количество полей составных типов, которые также в свою очередь имеют немалый вес.
Рассмотрим примеры таких задач. Для оценки затрат машинного времени на десериализацию данных будем использовать утилиту \textit{perf} и визуализацию её результатов с помощью flame-графов.

\subsection{Задача фильтрации списка массивных сообщений по легковесному полю}
\label{sec_problem:sec:problem1}

Представим задачу: микросервис принимает на вход в качестве запроса protobuf-сообщение \textit{UserInfo}, содержащее информацию о пользователе,
в том числе время его регистрации. Структура сообщения описана в листинге \ref{sec_problem:listing:userinfo}.

\begin{lstlisting}[style=CodeListing, label={sec_problem:listing:userinfo}, caption={Protobuf-сообщение UserInfo}]
message UserInfo {
    message RegistrationInfo {
        uint64 registration_timestamp = 1;
        uint64 registration_lon = 2;
        uint64 registration_lat = 3;
    };

    RegistrationInfo registration_info = 1;
    // other huge fields
    ... 
}
\end{lstlisting}

Если пользователь зарегистрировался менее чем месяц назад, необходимо отредактировать некоторые поля в сообщении вернуть изменённое сообщение,
иначе ~--~ вернуть сообщение без изменений. Ясно, что в такой задаче количество пользователей, подходящих под условие, достаточно мало.
Таким образом, машинное время напрасно расходуется на десериализацию большей части потока, ведь ради проверки одного поля типа \textit{uint64} парсится всё большое сообщение.
Намного разумнее в такой задаче было бы игнорировать десериализацию всех полей, кроме тех, к которым обращается алгоритм.

\subsection{Задача извлечения информации на большом уровне вложенности}
\label{sec_problem:sec:problem2}

Нередко в практике встречаются protobuf-сообщения с большим уровнем вложенности. Такой подход позволяет переиспользовать одни и те же сообщения в разных модулях
программы, держать меньшее количество полей в сообщениях, тем самым не нарушая читабельность, а также инкапсулировать данные максимально приближённо к реальному миру.
Однако десериализация такого рода сообщений, опять же, становится достаточно тяжёлой операцией, которая выполняет много лишней работы: зачастую бизнес-логика не задействует
абсолютно все поля полученного сообщения, а, напротив, пользуется малой их частью. Это приводит к тому, что большая часть работы по десериализации производится впустую.

В качестве примера можно привести следующую задачу. Пусть для обработки запроса из базы данных
изымается protobuf-сообщение, содержащее в себе всю информацию о пользователе, описанное в листинге \ref{sec_problem:listing:userinfo}.
Предположим, что серверная часть приложения работает на микросервисной архитектуре. Таким образом, не существует такого микросервиса,
которому понадобились бы сразу все поля сообщения \textit{UserInfo}, так как это противоречит принципу единственной ответственности.
Тогда имеем ситуацию, когда несколько сервисов десериализуют одно и то же protobuf-сообщение с целью изъятия необходимых данных.

\subsection{Пути решения поставленной проблемы}

Изучив алгоритм сериализации, используемый в протоколе, можно сделать следующие выводы:
\begin{itemize}
    \item формат сериализации структурирован: protobuf использует структурированный формат, который позволяет легко идентифицировать поля сообщения и их типы данных;
    \item кодирование с битовым выравниванием: protobuf использует кодирование с битовым выравниванием, что обеспечивает возможность легко вычислять границы необходимого поля в сериализованном сообщении.
\end{itemize}

Таким образом можно сделать вывод, что протокол позволяет реализовать неполную десериализацию сообщения.
В таком случае десериализатор будет просто пропускать бинарное представление неиспользуемых полей, не затрачивая время на их распаковку.
Рассмотрим две возможных реализации такого поведения.

\pagebreak

\subsubsection{Создание легковесной версии сообщения}

Благодаря необходимости поддержки обратной совместимости, стандарт Protocol Buffers допускает удаление ранее существующих полей из структуры сообщения.
При этом не нарушается работа десериализатора: если на вход пришло закодированное ранее сообщение, где удалённое поле всё ещё есть, десериализатор просто пропустит
этот участок и перейдёт к следущим полям. 
Также алгоритм сериализации никак не пользуется названиями типов данных сообщений или именами полей.
Воспользовавшись этими фактами, можно сделать вывод о корректности следующего решения: если создать <<легковесную>> версию сообщения, которая будет содержать подмножество
необходимых полей исходного сообщения, обязательно сохраняя их номера и типы данных, то сериализованное исходное сообщение корректно десериализуется в его <<лекговесный>>
тип, при этом десериализатор пропустит распаковку полей, которые не указаны в <<урезанной>> версии, тем самым сэкономив машинное время.

Например, для сообщения, описанного в листинге \ref{sec_problem:listing:userinfo}, в задаче, описанной в 
разделе \ref{sec_problem:sec:problem1}, легковесная версия представлена в листинге \ref{sec_problem:code:userinfolight}.
\begin{lstlisting}[style=CodeListing, label={sec_problem:code:userinfolight}, caption={Легковесная версия сообщения UserInfo}]
message UserInfoLight {
    UserInfo.RegistrationInfo registration_info = 1;
}
\end{lstlisting}

Теперь разработчик в логике фильтрации может распаковывать пришедшее сообщение в тип \textit{UserInfoLight} и алгоритм будет работать быстрее.

Однако у этого метода есть достаточно большое количество недостатков:
\begin{enumerate}
    \item Легковесную версию сообщения следует синхронизировать с основной. Может случиться ситуация, когда необходимое для логики поле будет удалено в основном сообщении, но не будет удалено в урезанной версии. Такие действия не разрушат компиляцию, так как с точки зрения компилятора это два независимых сообщения. Ошибка будет получена только во время выполнения. Следовательно, такие случаи нужно покрывать нетривиальными тестами и следить, чтобы они успешно выполнялись перед выходом новой версии;
    \item Для разных задач может понадобиться обращение к разным полям, что приводит либо к разрастанию урезанной версии сообщения, либо к порождению большого количества легковесных версий одного и того же сообщения, что тяжелее поддерживать;
    \item В сложных случаях обращение к каким-то из полей может производиться по условию в зависимости от логики обработки, однако такой подход не позволяет учесть этих условий и будет распаковывать необходимые поля всегда.
\end{enumerate}

\subsubsection{<<Ленивая>> десериализация} 

Более удобным решением данной проблемы является <<ленивая>> десериализация.
<<Ленивая>> десериализация (или десериализация по требованию) ~--~ это оптимизационная техника, используемая при десериализации данных из сериализованного формата. 
Она заключается в отложенной декодировке данных до тех пор, пока они не потребуются.

Предполагается, что <<ленивая>> десериализация Protobuf обеспечит значительное повышение производительности, особенно при работе с большими сообщениями.

В контексте Protobuf (Protocol Buffers) ленивая десериализация означает, что поля сообщения Protobuf декодируются только тогда, когда к ним осуществляется доступ, а не сразу после получения всего сообщения. 
Это может значительно улучшить производительность и уменьшить использование памяти, особенно при работе с большими сообщениями.
Также, такое решение лишено всех недостатков предыдущего описанного метода, так как решение о десериализации принимается во время выполнения программы.
В данной дипломной работе рассматривается реализация данного решения путём написания и внедрения соответствующего программного модуля в компилятор \textit{protoc}, замер и сравнение производительности на описанных ранее задачах против неизменённой версии компилятора.
