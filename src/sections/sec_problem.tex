\section{Постановка проблемы}

По заявлениям разработчиков, сериализация и десериализация сообщений происходит достаточно быстро, однако
на практике при работе с массивными protobuf-сообщениями существует ряд задач, в которых десериализация является самой затратной операцией.
Массивными будем называть сообщения, имеющие большое количество полей составных типов, которые также в свою очередб имеют немалый вес.
Рассмотрим примеры таких задач. Для оценки затрат машинного времени на десериализацию данных будем использовать утилиту \textit{perf} и визуализацию её результатов с помощью flame-графов.

\subsection{Задача фильтрации списка массивных сообщений по легковесному полю}
\label{sec_problem:sec:problem1}

Представим задачу: микросервис принимает на вход в качестве запроса protobuf-сообщение \textit{UserInfo}, содержащее информацию о пользователе,
в том числе время его :

\begin{lstlisting}[style=CodeListing, label={sec_problem:listing:userinfo}, caption={protobuf-сообщение UserInfo}]
    message UserInfo {
        message RegistrationInfo {
            uint64 registration_timestamp = 1;
            uint64 registration_lon = 2;
            uint64 registration_lat = 3;
        };

        RegistrationInfo registration_info = 1;
        // other huge fields
        ... 
    }
\end{lstlisting}

Если пользователь зарегистрировался менее чем месяц назад, необходимо отредактировать некоторые поля в сообщении вернуть изменённое сообщение,
иначе ~--~ вернуть сообщение без изменений. Ясно, что в такой задаче количество пользователей, подходящих под условие, достаточно мало.
Таким образом, машинное время напрасно расходуется на десериализацию большей части потока, ведь ради проверки одного поля типа \textit{uint64} парсится всё большое сообщение.
Намного разумнее в такой задаче было бы игнорировать десериализацию всех полей, кроме тех, к которым обращается алгоритм.

\subsection{Задача извлечения информации на большом уровне вложенности}

Нередко в практике встречаются protobuf-сообщения с большим уровнем вложенности. Такой подход позволяет переиспользовать одни и те же сообщения в разных модулях
программы, держать меньшее количество полей в сообщениях, тем самым не нарушая читабельность, а также инкапсулировать данные максимально приближённо к реальному миру.
Однако десериализация такого рода сообщений, опять же, становится достаточно тяжёлой операцией, которая выполняет много лишней работы: зачастую бизнес-логика не задействует
абсолютно все поля полученного сообщения, а, напротив, пользуется малой их частью. Это приводит к тому, что большая часть работы по десериализации производится впустую.

В качестве примера можно привести следующую задачу. Пусть для обработки запроса из базы данных
изымается protobuf-сообщение, содержащее в себе всю информацию о пользователе, описанное в листинге \ref{sec_problem:listing:userinfo}.
Предположим, что серверная часть приложения работает на микросервисной архитектуре. Таким образом, не существует такого микросервиса,
которому понадобились бы сразу все поля сообщения \textit{UserInfo}, так как это противоречит принципу единственной ответственности.
Тогда имеем ситуацию, когда несколько сервисов десериализуют одно и то же protobuf-сообщение с целью изъятия необходимых данных.
